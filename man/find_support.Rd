% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/find_support.R
\name{find_support}
\alias{find_support}
\title{Sample from the Posterior Distribution of the Linear Gaussian Feature
Allocation Model}
\usage{
find_support(weights, samplesizes, power2 = TRUE)
}
\arguments{
\item{massPriorShape}{Shape parameter of the gamma prior on the mass
parameter, where the expected value if \code{massPriorShape/massPriorRate}.}

\item{massPriorRate}{Rate parameter of the gamma prior on the mass parameter,
where the expected value if \code{massPriorShape/massPriorRate}.}

\item{maxStandardDeviationX}{Maximum value parameter of the uniform prior
distribution on the standard deviation of \code{X}.}

\item{maxStandardDeviationW}{Maximum value parameter of the uniform prior
distribution on the standard deviation of \code{W}.}

\item{sdProposedStandardDeviationX}{Standard deviation of the Gaussian random
walk update for the standard deviation of \code{X}.}

\item{sdProposedStandardDeviationW}{Standard deviation of the Gaussian random
walk update for the standard deviation of \code{W}.}

\item{corProposedSdXSdW}{Correlation of the multivariate Gaussian random walk
updates for the standard deviations of \code{X} and \code{W}.}

\item{nPerShuffle}{Number of items to randomly select and permute when
proposing an update to the permutation associated with the attraction
Indian buffet distribution (AIBD).}

\item{newFeaturesTruncationDivisor}{While in theory a countable infinite
number of new features may be allocated to an item, the posterior
simulation needs to limit the number of new features that are considered.
The value of this argument controls when to stop considering additional
features.  Starting with 0 and 1 new features, the posterior
probabililities are computed.  Additional new features of considered but
the algorithm stops when the posterior probabilities of the current number
of new features is less than the maximum posterior probability (among the
previous number of new features) dividided by
\code{newFeaturesTruncationDivisior}.}

\item{nSamples}{Number of feature allocations to return.  The actual number
of iterations of the algorithm is \code{thin*nSamples}.}

\item{thin}{Only save 1 in \code{thin} feature allocations.}

\item{rankOneUpdates}{Should rank one updates for the inverse and determinant
be used? In some cases, this may be faster.}

\item{verbose}{Should a progress bar and information regarding lapse time and
acceptance rates be displayed?}
}
\description{
This function samples from the posterior distribution of the linear Gaussian
latent feature model (LGLFM) using an Indian buffet process (IBP) prior on
the feature allocations.
}
\examples{
mass <- 1
sigx <- 0.1
sigw <- 1.0
dimW <- 1
nItems <- 8  # Should be a multiple of 4
dist <- ibp(mass, nItems)
Z <- matrix(c(1,0,1,1,0,1,0,0),byrow=TRUE,nrow=nItems,ncol=2)
Z <- Z[order(Z \%*\% c(2,1)),c(2,1)]
Ztruth <- Z
W <- matrix(rnorm(ncol(Z)*dimW,sd=sigw),nrow=ncol(Z),ncol=dimW)
e <- rnorm(nrow(Z)*ncol(W),0,sd=sigx)
X <- Z \%*\% W + e
samples <- samplePosteriorLGLFM(Z, dist, X, sdX=sigx, sdW=sigw, nSamples=1000, thin=1)
X <- matrix(double(),nrow=nrow(Z),ncol=0)
samples <- samplePosteriorLGLFM(Z, dist, X, sdX=sigx, sdW=sigw, nSamples=1000, thin=1)

library(sdols)
expectedPairwiseAllocationMatrix(samples$featureAllocation)
Ztruth \%*\% t(Ztruth)
plot(expectedPairwiseAllocationMatrix(samples$featureAllocation), Ztruth \%*\% t(Ztruth))

}
